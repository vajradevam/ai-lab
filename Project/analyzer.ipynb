{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import time\n",
    "from datetime import datetime\n",
    "from typing import Dict, List\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import yfinance as yf\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "from Modelyaga import big_model_baba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "KEY = os.environ['GEMINI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Gemini API\n",
    "genai.configure(api_key=KEY)  # Replace with your actual API key\n",
    "\n",
    "# Set up the model\n",
    "generation_config = {\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 1,\n",
    "    \"top_k\": 32,\n",
    "    \"max_output_tokens\": 4096,\n",
    "}\n",
    "\n",
    "safety_settings = [\n",
    "    {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
    "    {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
    "    {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
    "    {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
    "]\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-2.0-flash\",\n",
    "    generation_config=generation_config,\n",
    "    safety_settings=safety_settings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup():\n",
    "    # Define the directory\n",
    "    output_dir = \"TICKER_DATA\"\n",
    "\n",
    "    # Find all CSV files in the directory\n",
    "    files = glob.glob(os.path.join(output_dir, \"*.csv\"))\n",
    "\n",
    "    # Delete each file\n",
    "    for file in files:\n",
    "        try:\n",
    "            os.remove(file)\n",
    "            print(f\"Deleted: {file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting {file}: {e}\")\n",
    "\n",
    "    print(\"Cleanup completed. All CSV files deleted.\")\n",
    "\n",
    "def cleanup_csv_data(file):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # List of columns to set to NaN (all except Symbol, Company Name, Sector)\n",
    "    cols_to_nan = ['Previous Price', 'Predicted Price', 'Change ($)', 'Change (%)', \n",
    "                'New/Old Ratio', 'MSE', 'R2', 'Sentiment Score', 'Sentiment Validity']\n",
    "\n",
    "    # Set these columns to NaN\n",
    "    df[cols_to_nan] = np.nan\n",
    "\n",
    "    # Save or display the result\n",
    "    df.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_data():\n",
    "    # Create a directory to save data\n",
    "    output_dir = \"TICKER_DATA\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Load tickers from CSV (Assuming 'tickers.csv' has a column 'Symbol')\n",
    "    tickers_df = pd.read_csv(\"tickers.csv\")\n",
    "    tickers = tickers_df[\"Symbol\"].tolist()\n",
    "\n",
    "    # Define start and end dates (past 1 year)\n",
    "    end_date = pd.to_datetime(\"today\").strftime('%Y-%m-%d')\n",
    "    start_date = (pd.to_datetime(\"today\") - pd.DateOffset(years=1)).strftime('%Y-%m-%d')\n",
    "\n",
    "    # Fetch historical stock prices for each ticker and save separately\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            history = stock.history(start=start_date, end=end_date, interval=\"1d\")\n",
    "            if not history.empty:\n",
    "                history.reset_index(inplace=True)\n",
    "                history[\"Symbol\"] = ticker  # Add ticker column\n",
    "                \n",
    "                # Save as CSV\n",
    "                file_path = os.path.join(output_dir, f\"{ticker}.csv\")\n",
    "                history.to_csv(file_path, index=False)\n",
    "                print(f\"Saved: {file_path}\")\n",
    "            else:\n",
    "                print(f\"No data for {ticker}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {ticker}: {e}\")\n",
    "\n",
    "    print(f\"All stock data saved in '{output_dir}' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_update():\n",
    "    # Read the tickers information\n",
    "    tickers_info = pd.read_csv('tickers_ml.csv')\n",
    "\n",
    "    # Initialize lists to store all data\n",
    "    results = []\n",
    "\n",
    "    ticker_dir = \"./TICKER_DATA/\"\n",
    "    ticker_files = os.listdir(\"./TICKER_DATA/\")\n",
    "\n",
    "    # Process each file\n",
    "    for ticker_file in ticker_files:\n",
    "        ticker = ticker_file.split('.')[0]\n",
    "        file_path = os.path.join(ticker_dir, ticker_file)\n",
    "        \n",
    "        # Get predictions and stats\n",
    "        pred, stat = big_model_baba(file_path)\n",
    "        \n",
    "        # Read last actual price from CSV\n",
    "        df = pd.read_csv(file_path)\n",
    "        prev_price = df['Close'].iloc[-1]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        change_dollar = pred - prev_price\n",
    "        change_percent = (change_dollar / prev_price) * 100\n",
    "        new_old_ratio = pred / prev_price\n",
    "        \n",
    "        # Get company info from tickers_info\n",
    "        company_info = tickers_info[tickers_info['Symbol'] == ticker].iloc[0]\n",
    "        \n",
    "        # Create result dictionary\n",
    "        result = {\n",
    "            'Symbol': ticker,\n",
    "            'Company Name': company_info['Company Name'],\n",
    "            'Sector': company_info['Sector'],\n",
    "            'Previous Price': prev_price,\n",
    "            'Predicted Price': pred,\n",
    "            'Change ($)': change_dollar,\n",
    "            'Change (%)': change_percent,\n",
    "            'New/Old Ratio': new_old_ratio,\n",
    "            'MSE': stat['mse'],\n",
    "            'R2': stat['r2']\n",
    "            # Add any other stats from stat dictionary here\n",
    "        }\n",
    "        \n",
    "        results.append(result)\n",
    "        \n",
    "        # Print results in one row (optional)\n",
    "        # print(f\"{ticker:<6} | {prev_price:10.2f} | {pred:10.2f} | {change_dollar:8.2f} | {change_percent:8.2f}% | {new_old_ratio:8.4f} | {stat['mse']:8.2f} | {stat['r2']:8.4f}\")\n",
    "\n",
    "        # Create DataFrame from results\n",
    "        results_df = pd.DataFrame(results)\n",
    "\n",
    "        # Reorder columns if needed\n",
    "        columns_order = ['Symbol', 'Company Name', 'Sector', 'Previous Price', 'Predicted Price', \n",
    "                        'Change ($)', 'Change (%)', 'New/Old Ratio', 'MSE', 'R2']\n",
    "        results_df = results_df[columns_order]\n",
    "\n",
    "        # Save to CSV if desired\n",
    "        results_df.to_csv('tickers_ml.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news(ticker):\n",
    "    ticker = yf.Ticker(ticker)\n",
    "\n",
    "    news = ticker.news\n",
    "\n",
    "    news_text = \"\"\n",
    "\n",
    "    for item in news:\n",
    "        news_text += f\"Title: {item[\"content\"][\"title\"]}\\n\" + f\"Summary: {item[\"content\"][\"summary\"]}\\n\"\n",
    "\n",
    "    return news_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_news_sentiment(news_text: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Analyzes financial news text and returns sentiment analysis for mentioned tickers\n",
    "    \n",
    "    Args:\n",
    "        news_text: The financial news text to analyze\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries with ticker, sentiment score, and sentiment validity\n",
    "        Format: [{\"ticker\": str, \"sentiment score\": float, \"sentiment validity\": float}]\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"Analyze this financial news text and perform the following tasks:\n",
    "    \n",
    "    1. Identify all stock tickers mentioned (e.g., AAPL, MSFT, GOOGL)\n",
    "    2. For each ticker, determine the sentiment (positive/negative/neutral)\n",
    "    3. Assign a sentiment score between 0 (most negative) and 1 (most positive)\n",
    "    4. Assign a sentiment validity score between 0 (low confidence) and 1 (high confidence)\n",
    "       based on how clearly the sentiment is expressed for that ticker\n",
    "    \n",
    "    Return ONLY a JSON-formatted list of dictionaries with these keys:\n",
    "    - \"ticker\" (the stock symbol)\n",
    "    - \"sentiment score\" (0-1)\n",
    "    - \"sentiment validity\" (0-1)\n",
    "    \n",
    "    News text to analyze:\n",
    "    {news_text}\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        \n",
    "        # Extract JSON from the response\n",
    "        json_str = response.text.strip().replace('```json', '').replace('```', '').strip()\n",
    "        \n",
    "        # Parse the JSON string into Python objects\n",
    "        import json\n",
    "        result = json.loads(json_str)\n",
    "        \n",
    "        # Validate the structure\n",
    "        if not isinstance(result, list):\n",
    "            raise ValueError(\"Response is not a list\")\n",
    "            \n",
    "        for item in result:\n",
    "            if not all(key in item for key in [\"ticker\", \"sentiment score\", \"sentiment validity\"]):\n",
    "                raise ValueError(\"Missing required keys in response\")\n",
    "                \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing news: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_tickers_with_sentiment(csv_path: str, sentiment_results: List[Dict]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Updates the tickers CSV with sentiment analysis results\n",
    "    \n",
    "    Args:\n",
    "        csv_path: Path to the tickers CSV file\n",
    "        sentiment_results: List of sentiment analysis dictionaries from Gemini\n",
    "        \n",
    "    Returns:\n",
    "        Updated pandas DataFrame\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(csv_path)\n",
    "        \n",
    "        # Initialize new columns if they don't exist\n",
    "        if 'Sentiment Score' not in df.columns:\n",
    "            df['Sentiment Score'] = None\n",
    "        if 'Sentiment Validity' not in df.columns:\n",
    "            df['Sentiment Validity'] = None\n",
    "        \n",
    "        # Create a mapping from sentiment results for quick lookup\n",
    "        sentiment_map = {\n",
    "            item['ticker']: {\n",
    "                'score': item['sentiment score'],\n",
    "                'validity': item['sentiment validity']\n",
    "            }\n",
    "            for item in sentiment_results\n",
    "        }\n",
    "        \n",
    "        # Update the DataFrame\n",
    "        for index, row in df.iterrows():\n",
    "            ticker = row['Symbol']\n",
    "            if ticker in sentiment_map:\n",
    "                df.at[index, 'Sentiment Score'] = sentiment_map[ticker]['score']\n",
    "                df.at[index, 'Sentiment Validity'] = sentiment_map[ticker]['validity']\n",
    "        \n",
    "        # Optionally save back to CSV\n",
    "        df.to_csv(f\"tickers_news.csv\", index=False)\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error updating tickers CSV: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tickers_news():\n",
    "    for ticker in os.listdir(\"./TICKER_DATA/\"):\n",
    "        news_text = get_news(ticker[:-4])\n",
    "        sentiment_results = analyze_news_sentiment(news_text)\n",
    "        update_tickers_with_sentiment(\"./tickers_news.csv\", sentiment_results)\n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup()\n",
    "cleanup_csv_data(\"./tickers.csv\")\n",
    "cleanup_csv_data(\"./tickers_ml.csv\")\n",
    "cleanup_csv_data(\"./tickers_news.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ticker_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallely Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "def main():\n",
    "    # Create two separate processes\n",
    "    process1 = multiprocessing.Process(target=predict_and_update)\n",
    "    process2 = multiprocessing.Process(target=process_tickers_news)\n",
    "    \n",
    "    # Start both processes\n",
    "    process1.start()\n",
    "    process2.start()\n",
    "    \n",
    "    # Wait for both processes to complete\n",
    "    process1.join()\n",
    "    process2.join()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge ML Preds and Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_stock_data(prediction_file, sentiment_file, output_file):\n",
    "    # Read the files\n",
    "    predictions = pd.read_csv(prediction_file)\n",
    "    sentiments = pd.read_csv(sentiment_file)\n",
    "    \n",
    "    # Identify columns to add from sentiment file (excluding overlapping columns)\n",
    "    sentiment_cols_to_add = [col for col in sentiments.columns \n",
    "                           if col not in predictions.columns]\n",
    "    \n",
    "    # Merge while keeping all prediction columns and only adding sentiment columns\n",
    "    merged_data = predictions.merge(\n",
    "        sentiments[['Symbol', 'Company Name', 'Sector'] + sentiment_cols_to_add],\n",
    "        on=['Symbol', 'Company Name', 'Sector'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Save the merged data\n",
    "    merged_data.to_csv(output_file, index=False)\n",
    "    print(f\"Merged data saved to {output_file}\")\n",
    "    \n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_csv = \"tickers_ml.csv\"\n",
    "sentiment_csv = \"tickers_news.csv\"\n",
    "output_csv = \"tickers.csv\"\n",
    "\n",
    "result = merge_stock_data(prediction_csv, sentiment_csv, output_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_csv = \"tickers.csv\"\n",
    "df = pd.read_csv(input_csv)\n",
    "df['Relative_MSE'] = (df['MSE'] / (df['Previous Price'] ** 2)) * 100\n",
    "df.to_csv(input_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddff = pd.read_csv(\"./tickers.csv\")\n",
    "ddff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define weights and normalization constant\n",
    "alpha = 1.0  # weight for price momentum\n",
    "beta = 5.0   # weight for sentiment term\n",
    "gamma = 10.0  # weight for new/old ratio term\n",
    "delta = 1.0  # weight for R2\n",
    "epsilon = 1.0  # weight for MSE term\n",
    "\n",
    "# Read CSV file\n",
    "df = pd.read_csv('tickers.csv')\n",
    "\n",
    "# Compute the price momentum: predicted percentage change in price\n",
    "df['Price_Momentum'] = (df['Predicted Price'] - df['Previous Price']) / df['Previous Price']\n",
    "\n",
    "# Compute the sentiment term: product of sentiment score and its validity\n",
    "df['Sentiment_Term'] = df['Sentiment Score'] * df['Sentiment Validity']\n",
    "\n",
    "# Compute the adjusted new/old ratio term: centered around 0\n",
    "df['Relative_Ratio'] = df['New/Old Ratio'] - 1\n",
    "\n",
    "# Compute the composite signal using the proposed formula\n",
    "df['Signal'] = (\n",
    "    alpha * df['Price_Momentum'] +\n",
    "    beta * df['Sentiment_Term'] +\n",
    "    gamma * df['Relative_Ratio'] +\n",
    "    delta * df['R2'] -\n",
    "    epsilon * (df['Relative_MSE'])\n",
    ")\n",
    "\n",
    "df = df.sort_values(by='Signal', ascending=False)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df.to_csv(\"final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
